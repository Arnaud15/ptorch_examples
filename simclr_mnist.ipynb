{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ab60e1-1dbb-4a3f-837e-2cca89d351b7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe643a4-c855-40eb-866a-39bb10564604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.simclr as simclr\n",
    "from src.data_loading import (\n",
    "    get_data_loader,\n",
    "    get_image_dataset,\n",
    "    subset_classes,\n",
    "    transforms_image_net,\n",
    ")\n",
    "from src.models import ResNet\n",
    "from src.train import training_loop\n",
    "from src.utils import accuracy, show, update_ewma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854634d1-4d4e-411e-8e3a-bca3427c796b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def train_simclr(\n",
    "    data: DataLoader,\n",
    "    model: nn.Module,\n",
    "    lr: float,\n",
    "    decay: float,\n",
    "    n_epochs: int = 100,\n",
    "    plot_every: int = 10,\n",
    "    print_every: int = 10,\n",
    "    write_every: int = 10,\n",
    "):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=decay)\n",
    "    transform = transforms_image_net(is_image=False, crop=True, crop_size=28)\n",
    "    writer = SummaryWriter(\"data/logs/simclr\")\n",
    "    running_acc = None\n",
    "    running_loss = None\n",
    "    for e_ix in range(n_epochs):\n",
    "        for (step_ix, batch) in enumerate(data):\n",
    "            x = batch[0]\n",
    "            package, loss, logits_labels = simclr.step(x, model, transform)\n",
    "            (t1, t2, s1, s2) = package\n",
    "            logits, labels = logits_labels\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = accuracy(logits, labels)\n",
    "            running_acc = update_ewma(acc.item(), running_acc, 0.9)\n",
    "            running_loss = update_ewma(loss.item(), running_loss, 0.9)\n",
    "\n",
    "        if write_every and (e_ix + 1) % write_every == 0:\n",
    "            writer.add_scalar(\"Accuracy\", running_acc, e_ix)\n",
    "            writer.add_scalar(\"Loss\", running_loss, e_ix)\n",
    "        if plot_every and ((e_ix == 1) or (e_ix + 1) % plot_every == 0):\n",
    "            show(torch.cat([x[:5], t1[:5], t2[:5]]))\n",
    "        if print_every and (e_ix + 1) % print_every == 0:\n",
    "            print(f\"loss: {loss.item()}\")\n",
    "            print(f\"contrastive accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd11a04-c6c0-43a0-8c1f-6753dac95919",
   "metadata": {},
   "source": [
    "### Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e89ed4-2b82-47f9-8429-3758e46e6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_image_dataset(\"mnist\", train=True,)\n",
    "train_two_balanced = subset_classes(\n",
    "    train_dataset, classes_retained=[0, 1], class_probas=[0.1, 0.1]\n",
    ")\n",
    "train_two_imbalanced = subset_classes(\n",
    "    train_dataset, classes_retained=[0, 1], class_probas=[0.5, 0.05]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4b072-2888-4815-9a77-6ce3c89e3865",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9c7c8d-1ac4-49e2-b160-2743c80de09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 128\n",
    "n_epochs = 100\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d9d578c-731a-4ec2-bca9-55acc07b30f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lengths: train-3274, val-0\n",
      "Dataset lengths: train-1288, val-0\n"
     ]
    }
   ],
   "source": [
    "train_loader, _ = get_data_loader(\n",
    "    train_two_imbalanced, val_share=0.0, batch_size=b_size, single_batch=False\n",
    ")\n",
    "eval_loader, _ = get_data_loader(\n",
    "    train_two_balanced, val_share=0.0, batch_size=b_size, single_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7a3786-17b1-4b0b-9698-ae96ec805362",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    # nn.LayerNorm((16, 14, 14)),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    # nn.LayerNorm((32, 7, 7)),\n",
    "    nn.Conv2d(32, 64, kernel_size=1, padding=0),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    ")\n",
    "head = nn.Sequential(nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 64))\n",
    "model = simclr.ContrastiveLearner(encoder=encoder, projection=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f8fcc-6952-4678-ad75-6ac06ca7ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.828437805175781\n",
      "contrastive accuracy: 0.013513513840734959\n",
      "loss: 4.7747721672058105\n",
      "contrastive accuracy: 0.013513513840734959\n",
      "loss: 5.1745076179504395\n",
      "contrastive accuracy: 0.006756756920367479\n"
     ]
    }
   ],
   "source": [
    "train_simclr(\n",
    "    train_loader,\n",
    "    model,\n",
    "    n_epochs=n_epochs,\n",
    "    plot_every=0,\n",
    "    print_every=10,\n",
    "    write_every=1,\n",
    "    lr=lr,\n",
    "    decay=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93004122-1308-4e9a-99b0-cda3f53cb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    # nn.LayerNorm((16, 14, 14)),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    # nn.LayerNorm((32, 7, 7)),\n",
    "    nn.Conv2d(32, 64, kernel_size=1, padding=0),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    ")\n",
    "training_loop(\n",
    "    \"test-mnist\",\n",
    "    model=encoder,\n",
    "    opt=torch.optim.SGD(encoder.parameters(), lr=lr, weight_decay=1e-6),\n",
    "    scheduler=None,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=eval_loader,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    device=\"cpu\",\n",
    "    n_epochs=100,\n",
    "    print_every=10,\n",
    "    write_every=10,\n",
    "    plot_every=0,\n",
    "    check_every=0,\n",
    "    metric_fn=accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5649b-7fa2-4c19-8d93-42e8ff8aee9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
