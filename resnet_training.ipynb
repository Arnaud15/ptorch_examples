{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcf344c-43f6-4ae1-a9be-35185f3a7bc0",
   "metadata": {},
   "source": [
    "## ResNet training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06132d9f-d8c0-46b0-a62a-1dcc614c2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.args import ResNetExpArgs, TrainingArgs, to_exp_name\n",
    "from src.data_loading import get_image_data_loader, transforms_image_net\n",
    "from src.models import MLP, ResNet\n",
    "from src.test import test_loop\n",
    "from src.train import training_loop\n",
    "from src.utils import accuracy, get_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa28d56d-3d7a-4511-a414-d136f70b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcec6f-b0de-4fcd-a035-92744145f98a",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852e31c5-c667-4c8f-bb38-f8b00124e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', 'mnist_128_0.1_1_0.9_0.0001_True_0_2_0.1_0.5_True_True_False')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ResNetExpArgs(\n",
    "    batch_size=128,\n",
    "    dataset_name=\"mnist\",\n",
    "    learning_rate=0.1,\n",
    "    num_epochs=1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0001,\n",
    "    cosine_lr=True,\n",
    "    warmup_epochs=0,\n",
    "    decay_interval=2,\n",
    "    decay_gamma=0.1,\n",
    "    mixup_alpha=0.5,\n",
    "    lean_stem=True,\n",
    "    smart_downsampling=True,\n",
    "    use_gpu=False,\n",
    ")\n",
    "\n",
    "training_args = TrainingArgs(\n",
    "    args.batch_size,\n",
    "    10,  # num classes\n",
    "    args.num_epochs,\n",
    "    args.cosine_lr,\n",
    "    args.warmup_epochs,\n",
    "    args.decay_interval,\n",
    "    args.decay_gamma,\n",
    "    args.mixup_alpha,\n",
    "    print_every=1,\n",
    "    write_every=1,\n",
    "    plot_every=10,\n",
    "    check_every=0,\n",
    ")\n",
    "\n",
    "dataset_to_n_classes = {\n",
    "    \"mnist\": 10,\n",
    "    \"cifar10\": 10,\n",
    "    \"fmnist\": 10,\n",
    "}\n",
    "\n",
    "exp_name = to_exp_name(args)\n",
    "device = \"cuda\" if args.use_gpu else \"cpu\"\n",
    "if args.use_gpu:\n",
    "    assert torch.cuda.is_available()\n",
    "device, exp_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fd92d-c5f4-45c4-b020-a055be41f5be",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657b1add-05ce-4268-a035-b62b71bcb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lengths: train-54000, val-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud15/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630778054/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms_image_net(\n",
    "    crop=True,\n",
    "    crop_size=28,\n",
    "    flip=True,\n",
    "    colors=True,\n",
    "    standardize=False,\n",
    "    is_image=True,\n",
    ")\n",
    "\n",
    "train_data, eval_data = get_image_data_loader(\n",
    "    args.dataset_name,\n",
    "    train=True,\n",
    "    val_share=0.1,\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size,\n",
    "    single_batch=False,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96280c21-f618-427b-94d6-502d08f86e8b",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282f96c7-e47e-48c2-bba1-b8b715d460bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet version\n",
    "# resnet_imagenet = Resnet(\n",
    "# img_channels=3,\n",
    "# n_classes=10,\n",
    "# extra_blocks_per_layer=[1, 3, 5, 2,],\n",
    "# resnet_channels=[64, 128, 256, 512],\n",
    "# stem_channels=64,\n",
    "# stem_downsample=True,\n",
    "# )\n",
    "# Cifar10 version\n",
    "# resnet_cifar = ResNet(\n",
    "#     img_channels=3,\n",
    "#     n_classes=10,\n",
    "#     extra_blocks_per_layer=[5, 5, 5],\n",
    "#     resnet_channels=[16, 32, 64],\n",
    "#     stem_channels=16,\n",
    "#     stem_conv_size=7 if not args.lean_stem else 3,\n",
    "#     stem_downsample=False,\n",
    "#     slender_stem=args.lean_stem,\n",
    "#     better_downsampling=args.smart_downsampling,\n",
    "# )\n",
    "# print(summary(resnet_cifar.to(device), (3, 32, 32)))\n",
    "baby_resnet = ResNet(\n",
    "    img_channels=1,\n",
    "    n_classes=10,\n",
    "    extra_blocks_per_layer=[1, 1],\n",
    "    resnet_channels=[16, 32,],\n",
    "    stem_channels=16,\n",
    "    stem_downsample=False,\n",
    "    slender_stem=True,\n",
    "    better_downsampling=True,\n",
    ")\n",
    "model = baby_resnet\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d1940-c8a0-4cbb-a9c3-377a4ec24582",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7371630f-e4ed-43ca-8c61-428c361c59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts for mnist_mixup\n",
      "Post-warmup begins\n",
      "Start of epoch 1\n",
      "Step: 1 | Training Loss: 1.87148\n",
      "Step: 1 | Training Metric: 0.52344\n",
      "Step: 2 | Training Loss: 1.90643\n",
      "Step: 2 | Training Metric: 0.54688\n",
      "Step: 3 | Training Loss: 1.87435\n",
      "Step: 3 | Training Metric: 0.54688\n",
      "Step: 4 | Training Loss: 1.85099\n",
      "Step: 4 | Training Metric: 0.60156\n",
      "Step: 5 | Training Loss: 1.72477\n",
      "Step: 5 | Training Metric: 0.63281\n",
      "Step: 6 | Training Loss: 1.72915\n",
      "Step: 6 | Training Metric: 0.67969\n",
      "Step: 7 | Training Loss: 1.99270\n",
      "Step: 7 | Training Metric: 0.79688\n",
      "Step: 8 | Training Loss: 1.80596\n",
      "Step: 8 | Training Metric: 0.59375\n",
      "Step: 9 | Training Loss: 2.06831\n",
      "Step: 9 | Training Metric: 0.74219\n",
      "Step: 10 | Training Loss: 1.99760\n",
      "Step: 10 | Training Metric: 0.75781\n",
      "Step: 11 | Training Loss: 1.73777\n",
      "Step: 11 | Training Metric: 0.75781\n",
      "Step: 12 | Training Loss: 1.92045\n",
      "Step: 12 | Training Metric: 0.75781\n",
      "Step: 13 | Training Loss: 1.54518\n",
      "Step: 13 | Training Metric: 0.75000\n",
      "Step: 14 | Training Loss: 1.98052\n",
      "Step: 14 | Training Metric: 0.72656\n",
      "Step: 15 | Training Loss: 1.71428\n",
      "Step: 15 | Training Metric: 0.77344\n",
      "Step: 16 | Training Loss: 1.49519\n",
      "Step: 16 | Training Metric: 0.76562\n",
      "Step: 17 | Training Loss: 1.59236\n",
      "Step: 17 | Training Metric: 0.67188\n",
      "Step: 18 | Training Loss: 1.52943\n",
      "Step: 18 | Training Metric: 0.84375\n",
      "Step: 19 | Training Loss: 1.64350\n",
      "Step: 19 | Training Metric: 0.88281\n",
      "Step: 20 | Training Loss: 1.81252\n",
      "Step: 20 | Training Metric: 0.81250\n",
      "Step: 21 | Training Loss: 1.53896\n",
      "Step: 21 | Training Metric: 0.78906\n",
      "Step: 22 | Training Loss: 1.79881\n",
      "Step: 22 | Training Metric: 0.85938\n",
      "Step: 23 | Training Loss: 1.87349\n",
      "Step: 23 | Training Metric: 0.81250\n",
      "Step: 24 | Training Loss: 1.89415\n",
      "Step: 24 | Training Metric: 0.83594\n",
      "Step: 25 | Training Loss: 1.78791\n",
      "Step: 25 | Training Metric: 0.82031\n",
      "Step: 26 | Training Loss: 1.61091\n",
      "Step: 26 | Training Metric: 0.81250\n",
      "Step: 27 | Training Loss: 1.68997\n",
      "Step: 27 | Training Metric: 0.76562\n",
      "Step: 28 | Training Loss: 1.74030\n",
      "Step: 28 | Training Metric: 0.87500\n",
      "Step: 29 | Training Loss: 1.49756\n",
      "Step: 29 | Training Metric: 0.73438\n",
      "Step: 30 | Training Loss: 1.79512\n",
      "Step: 30 | Training Metric: 0.84375\n",
      "Step: 31 | Training Loss: 1.56449\n",
      "Step: 31 | Training Metric: 0.89062\n",
      "Step: 32 | Training Loss: 1.51518\n",
      "Step: 32 | Training Metric: 0.77344\n",
      "Step: 33 | Training Loss: 1.47400\n",
      "Step: 33 | Training Metric: 0.77344\n",
      "Step: 34 | Training Loss: 1.80917\n",
      "Step: 34 | Training Metric: 0.81250\n",
      "Step: 35 | Training Loss: 1.50008\n",
      "Step: 35 | Training Metric: 0.83594\n",
      "Step: 36 | Training Loss: 1.88391\n",
      "Step: 36 | Training Metric: 0.86719\n",
      "Step: 37 | Training Loss: 1.47533\n",
      "Step: 37 | Training Metric: 0.83594\n",
      "Step: 38 | Training Loss: 1.51863\n",
      "Step: 38 | Training Metric: 0.87500\n",
      "Step: 39 | Training Loss: 1.48831\n",
      "Step: 39 | Training Metric: 0.83594\n",
      "Step: 40 | Training Loss: 1.74759\n",
      "Step: 40 | Training Metric: 0.85938\n",
      "Step: 41 | Training Loss: 1.44301\n",
      "Step: 41 | Training Metric: 0.78906\n",
      "Step: 42 | Training Loss: 1.51912\n",
      "Step: 42 | Training Metric: 0.83594\n",
      "Step: 43 | Training Loss: 1.71209\n",
      "Step: 43 | Training Metric: 0.83594\n",
      "Step: 44 | Training Loss: 1.49658\n",
      "Step: 44 | Training Metric: 0.88281\n",
      "Step: 45 | Training Loss: 1.62249\n",
      "Step: 45 | Training Metric: 0.89844\n",
      "Step: 46 | Training Loss: 1.46839\n",
      "Step: 46 | Training Metric: 0.88281\n",
      "Step: 47 | Training Loss: 1.56546\n",
      "Step: 47 | Training Metric: 0.88281\n",
      "Step: 48 | Training Loss: 1.38229\n",
      "Step: 48 | Training Metric: 0.90625\n",
      "Step: 49 | Training Loss: 1.50976\n",
      "Step: 49 | Training Metric: 0.75000\n",
      "Step: 50 | Training Loss: 1.71079\n",
      "Step: 50 | Training Metric: 0.82812\n",
      "Step: 51 | Training Loss: 1.68870\n",
      "Step: 51 | Training Metric: 0.82031\n",
      "Step: 52 | Training Loss: 1.49201\n",
      "Step: 52 | Training Metric: 0.84375\n",
      "Step: 53 | Training Loss: 1.49620\n",
      "Step: 53 | Training Metric: 0.89844\n",
      "Step: 54 | Training Loss: 1.45004\n",
      "Step: 54 | Training Metric: 0.74219\n",
      "Step: 55 | Training Loss: 1.50002\n",
      "Step: 55 | Training Metric: 0.79688\n",
      "Step: 56 | Training Loss: 1.43999\n",
      "Step: 56 | Training Metric: 0.77344\n",
      "Step: 57 | Training Loss: 1.50148\n",
      "Step: 57 | Training Metric: 0.90625\n",
      "Step: 58 | Training Loss: 1.53477\n",
      "Step: 58 | Training Metric: 0.85938\n",
      "Step: 59 | Training Loss: 1.51378\n",
      "Step: 59 | Training Metric: 0.70312\n",
      "Step: 60 | Training Loss: 1.39161\n",
      "Step: 60 | Training Metric: 0.85938\n",
      "Step: 61 | Training Loss: 1.46037\n",
      "Step: 61 | Training Metric: 0.77344\n",
      "Step: 62 | Training Loss: 1.54967\n",
      "Step: 62 | Training Metric: 0.82812\n",
      "Step: 63 | Training Loss: 1.41405\n",
      "Step: 63 | Training Metric: 0.83594\n",
      "Step: 64 | Training Loss: 1.43467\n",
      "Step: 64 | Training Metric: 0.72656\n",
      "Step: 65 | Training Loss: 1.36051\n",
      "Step: 65 | Training Metric: 0.92188\n",
      "Step: 66 | Training Loss: 1.40571\n",
      "Step: 66 | Training Metric: 0.78125\n",
      "Step: 67 | Training Loss: 1.37807\n",
      "Step: 67 | Training Metric: 0.85156\n",
      "Step: 68 | Training Loss: 1.43706\n",
      "Step: 68 | Training Metric: 0.90625\n",
      "Step: 69 | Training Loss: 1.40275\n",
      "Step: 69 | Training Metric: 0.85938\n",
      "Step: 70 | Training Loss: 1.39098\n",
      "Step: 70 | Training Metric: 0.90625\n",
      "Step: 71 | Training Loss: 1.42564\n",
      "Step: 71 | Training Metric: 0.78125\n",
      "Step: 72 | Training Loss: 1.56340\n",
      "Step: 72 | Training Metric: 0.73438\n",
      "Step: 73 | Training Loss: 1.45926\n",
      "Step: 73 | Training Metric: 0.79688\n",
      "Step: 74 | Training Loss: 1.49483\n",
      "Step: 74 | Training Metric: 0.78125\n",
      "Step: 75 | Training Loss: 1.42171\n",
      "Step: 75 | Training Metric: 0.82031\n",
      "Step: 76 | Training Loss: 1.47638\n",
      "Step: 76 | Training Metric: 0.86719\n",
      "Step: 77 | Training Loss: 1.51845\n",
      "Step: 77 | Training Metric: 0.92969\n",
      "Step: 78 | Training Loss: 1.32382\n",
      "Step: 78 | Training Metric: 0.94531\n",
      "Step: 79 | Training Loss: 1.36345\n",
      "Step: 79 | Training Metric: 0.87500\n",
      "Step: 80 | Training Loss: 1.40742\n",
      "Step: 80 | Training Metric: 0.90625\n",
      "Step: 81 | Training Loss: 1.52523\n",
      "Step: 81 | Training Metric: 0.89844\n",
      "Step: 82 | Training Loss: 1.30199\n",
      "Step: 82 | Training Metric: 0.89844\n",
      "Step: 83 | Training Loss: 1.54826\n",
      "Step: 83 | Training Metric: 0.89844\n",
      "Step: 84 | Training Loss: 1.43879\n",
      "Step: 84 | Training Metric: 0.88281\n",
      "Step: 85 | Training Loss: 1.55739\n",
      "Step: 85 | Training Metric: 0.84375\n",
      "Step: 86 | Training Loss: 1.43069\n",
      "Step: 86 | Training Metric: 0.75000\n",
      "Step: 87 | Training Loss: 1.39993\n",
      "Step: 87 | Training Metric: 0.90625\n",
      "Step: 88 | Training Loss: 1.51666\n",
      "Step: 88 | Training Metric: 0.88281\n",
      "Step: 89 | Training Loss: 1.37585\n",
      "Step: 89 | Training Metric: 0.92969\n",
      "Step: 90 | Training Loss: 1.38664\n",
      "Step: 90 | Training Metric: 0.86719\n",
      "Step: 91 | Training Loss: 1.28989\n",
      "Step: 91 | Training Metric: 0.92188\n",
      "Step: 92 | Training Loss: 1.32708\n",
      "Step: 92 | Training Metric: 0.86719\n",
      "Step: 93 | Training Loss: 1.38475\n",
      "Step: 93 | Training Metric: 0.92188\n",
      "Step: 94 | Training Loss: 1.36651\n",
      "Step: 94 | Training Metric: 0.89062\n",
      "Step: 95 | Training Loss: 1.43319\n",
      "Step: 95 | Training Metric: 0.88281\n",
      "Step: 96 | Training Loss: 1.41952\n",
      "Step: 96 | Training Metric: 0.84375\n",
      "Step: 97 | Training Loss: 1.40256\n",
      "Step: 97 | Training Metric: 0.89062\n",
      "Step: 98 | Training Loss: 1.53041\n",
      "Step: 98 | Training Metric: 0.85156\n",
      "Step: 99 | Training Loss: 1.38702\n",
      "Step: 99 | Training Metric: 0.85938\n",
      "Step: 100 | Training Loss: 1.52646\n",
      "Step: 100 | Training Metric: 0.90625\n",
      "Step: 101 | Training Loss: 1.48383\n",
      "Step: 101 | Training Metric: 0.79688\n",
      "Step: 102 | Training Loss: 1.37919\n",
      "Step: 102 | Training Metric: 0.83594\n",
      "Step: 103 | Training Loss: 1.38684\n",
      "Step: 103 | Training Metric: 0.89844\n",
      "Step: 104 | Training Loss: 1.33640\n",
      "Step: 104 | Training Metric: 0.93750\n",
      "Step: 105 | Training Loss: 1.20429\n",
      "Step: 105 | Training Metric: 0.92969\n",
      "Step: 106 | Training Loss: 1.38390\n",
      "Step: 106 | Training Metric: 0.72656\n",
      "Step: 107 | Training Loss: 1.46393\n",
      "Step: 107 | Training Metric: 0.85156\n",
      "Step: 108 | Training Loss: 1.31720\n",
      "Step: 108 | Training Metric: 0.89844\n",
      "Step: 109 | Training Loss: 1.38248\n",
      "Step: 109 | Training Metric: 0.78906\n",
      "Step: 110 | Training Loss: 1.25673\n",
      "Step: 110 | Training Metric: 0.92969\n",
      "Step: 111 | Training Loss: 1.28192\n",
      "Step: 111 | Training Metric: 0.92969\n",
      "Step: 112 | Training Loss: 1.28088\n",
      "Step: 112 | Training Metric: 0.88281\n",
      "Step: 113 | Training Loss: 1.32538\n",
      "Step: 113 | Training Metric: 0.88281\n",
      "Step: 114 | Training Loss: 1.50222\n",
      "Step: 114 | Training Metric: 0.85938\n",
      "Step: 115 | Training Loss: 1.32459\n",
      "Step: 115 | Training Metric: 0.88281\n",
      "Step: 116 | Training Loss: 1.10626\n",
      "Step: 116 | Training Metric: 0.92969\n",
      "Step: 117 | Training Loss: 1.38001\n",
      "Step: 117 | Training Metric: 0.87500\n",
      "Step: 118 | Training Loss: 1.28476\n",
      "Step: 118 | Training Metric: 0.92969\n",
      "Step: 119 | Training Loss: 1.38356\n",
      "Step: 119 | Training Metric: 0.90625\n",
      "Step: 120 | Training Loss: 1.33934\n",
      "Step: 120 | Training Metric: 0.85938\n",
      "Step: 121 | Training Loss: 1.43340\n",
      "Step: 121 | Training Metric: 0.80469\n",
      "Step: 122 | Training Loss: 1.38264\n",
      "Step: 122 | Training Metric: 0.85156\n",
      "Step: 123 | Training Loss: 1.53361\n",
      "Step: 123 | Training Metric: 0.88281\n",
      "Step: 124 | Training Loss: 1.30713\n",
      "Step: 124 | Training Metric: 0.85156\n",
      "Step: 125 | Training Loss: 1.30895\n",
      "Step: 125 | Training Metric: 0.92969\n",
      "Step: 126 | Training Loss: 1.43708\n",
      "Step: 126 | Training Metric: 0.85938\n",
      "Step: 127 | Training Loss: 1.31142\n",
      "Step: 127 | Training Metric: 0.88281\n",
      "Step: 128 | Training Loss: 1.37123\n",
      "Step: 128 | Training Metric: 0.78125\n",
      "Step: 129 | Training Loss: 1.43724\n",
      "Step: 129 | Training Metric: 0.82031\n",
      "Step: 130 | Training Loss: 1.23168\n",
      "Step: 130 | Training Metric: 0.89844\n",
      "Step: 131 | Training Loss: 1.44085\n",
      "Step: 131 | Training Metric: 0.92188\n",
      "Step: 132 | Training Loss: 1.29582\n",
      "Step: 132 | Training Metric: 0.88281\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13619/659827075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m training_loop(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"mnist_mixup\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ptorch_examples/src/train.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(name, args, model, opt, train_loader, eval_loader, loss_fn, device, metric_fn)\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Post-warmup begins\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     inner_train(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ptorch_examples/src/train.py\u001b[0m in \u001b[0;36minner_train\u001b[0;34m(name, args, model, opt, scheduler, train_loader, eval_loader, loss_fn, device, metric_fn)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Start of epoch {epoch_ix + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msaturation_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhue_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_saturation\u001b[0;34m(img, saturation_factor)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \"\"\"\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36madjust_saturation\u001b[0;34m(img, saturation_factor)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0menhancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegenerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptorch/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \"\"\"\n\u001b[1;32m   1150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0m__copy__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "no_decay, decay = model.get_params()\n",
    "optimizer = get_optimizer(\n",
    "    decay_params=decay,\n",
    "    no_decay_params=no_decay,\n",
    "    lr=args.learning_rate,\n",
    "    momentum=args.momentum,\n",
    "    weight_decay=args.weight_decay,\n",
    ")\n",
    "\n",
    "if args.mixup_alpha is not None:\n",
    "    loss_fn = lambda inputs, targets: nn.KLDivLoss(reduction=\"batchmean\")(\n",
    "        nn.LogSoftmax(dim=1)(inputs), targets\n",
    "    )\n",
    "else:\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "training_loop(\n",
    "    \"mnist_mixup\",\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    opt=optimizer,\n",
    "    train_loader=train_data,\n",
    "    eval_loader=eval_data,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    metric_fn=accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4df30-bc92-479d-9a11-ecea0a746c48",
   "metadata": {},
   "source": [
    "### Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6c0cc-e2fe-41dd-a70d-c3adc6ce4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.load(\n",
    "    os.path.join(os.path.join(\"data\", \"checkpoints\"), f\"{exp_name}-70000.pt\"),\n",
    "    map_location=device,\n",
    ")\n",
    "model.load_state_dict(loaded[\"model_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8ac43-84fe-4a80-952d-9faa3458a96e",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5372f-e76b-41d8-80dd-1856c2c074de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, should_be_none = get_image_data_loader(\n",
    "    args.dataset_name,\n",
    "    train=False,\n",
    "    val_share=0.1,\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size,\n",
    "    single_batch=False,\n",
    ")\n",
    "assert should_be_none is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa89803-602e-4d2c-8a16-269f95016eef",
   "metadata": {},
   "source": [
    "### Evaluate the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464b1cf-6dcd-4f74-bfbb-7f8e83be0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(\n",
    "    test_loader=test_loader,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    metric_fn=accuracy,\n",
    "    plot=True,\n",
    "    loss_fn=F.cross_entropy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aebfe-30f1-44a6-a841-9bad7dbb3b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
