{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcf344c-43f6-4ae1-a9be-35185f3a7bc0",
   "metadata": {},
   "source": [
    "## ResNet training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06132d9f-d8c0-46b0-a62a-1dcc614c2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import test_loop\n",
    "from data_loading import get_image_data_loader, transforms_image_net\n",
    "from models import ResNet, MLP\n",
    "from train import training_loop\n",
    "from utils import accuracy, get_optimizer\n",
    "from args import ResNetTrainingArgs, to_exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa28d56d-3d7a-4511-a414-d136f70b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcec6f-b0de-4fcd-a035-92744145f98a",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852e31c5-c667-4c8f-bb38-f8b00124e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda',\n",
       " 'cifar10_128_0.1_120_0.9_0.0001_True_5_2_0.1_0.5_False_False_False_True')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ResNetTrainingArgs(batch_size=128,\n",
    "                          dataset_name=\"cifar10\",\n",
    "                          learning_rate=0.1,\n",
    "                          num_epochs=120,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=0.0001,\n",
    "                          cosine_lr=True,\n",
    "                          warmup_epochs=5,\n",
    "                          decay_interval=2,\n",
    "                          decay_gamma=0.1,\n",
    "                          mixup_alpha=0.5,\n",
    "                          mixup_enabled=False,\n",
    "                          lean_stem=False,\n",
    "                          smart_downsampling=False,\n",
    "                          use_gpu=True)\n",
    "\n",
    "dataset_to_n_classes = {\n",
    "    \"mnist\": 10,\n",
    "    \"cifar10\": 10,\n",
    "    \"fmnist\": 10,\n",
    "}\n",
    "\n",
    "exp_name = to_exp_name(args)\n",
    "device = \"cuda\" if args.use_gpu else \"cpu\"\n",
    "if args.use_gpu:\n",
    "    assert torch.cuda.is_available()\n",
    "device, exp_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fd92d-c5f4-45c4-b020-a055be41f5be",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657b1add-05ce-4268-a035-b62b71bcb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset lengths: train-45000, val-5000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms_image_net(\n",
    "    crop=True,\n",
    "    crop_size=28,\n",
    "    flip=True,\n",
    "    colors=True,\n",
    "    standardize=False,)\n",
    "\n",
    "train_data, eval_data = get_image_data_loader(\n",
    "    args.dataset_name,\n",
    "    train=True,\n",
    "    val_share=0.1,\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size,\n",
    "    single_batch=False,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96280c21-f618-427b-94d6-502d08f86e8b",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282f96c7-e47e-48c2-bba1-b8b715d460bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet version\n",
    "# resnet_imagenet = Resnet(\n",
    "# img_channels=3,\n",
    "# n_classes=10,\n",
    "# extra_blocks_per_layer=[1, 3, 5, 2,],\n",
    "# resnet_channels=[64, 128, 256, 512],\n",
    "# stem_channels=64,\n",
    "# stem_downsample=True,\n",
    "# )\n",
    "# Cifar10 version\n",
    "resnet_cifar = ResNet(\n",
    "    img_channels=3,\n",
    "    n_classes=10,\n",
    "    extra_blocks_per_layer=[5, 5, 5],\n",
    "    resnet_channels=[16, 32, 64],\n",
    "    stem_channels=16,\n",
    "    stem_downsample=False,\n",
    ")\n",
    "# print(summary(resnet_cifar, (3, 32, 32)))\n",
    "# baby_resnet = ResNet(\n",
    "#     img_channels=1,\n",
    "#     n_classes=10,\n",
    "#     extra_blocks_per_layer=[1, 1, 1],\n",
    "#     resnet_channels=[16, 32, 64],\n",
    "#     stem_channels=16,\n",
    "#     stem_downsample=False,\n",
    "# )\n",
    "model = resnet_cifar\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d1940-c8a0-4cbb-a9c3-377a4ec24582",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371630f-e4ed-43ca-8c61-428c361c59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts for cifar10_128_0.1_120_0.9_0.0001_True_5_2_0.1_0.5_False_False_False_True\n",
      "Warmup begins\n",
      "Start of epoch 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training starts for {exp_name}\")\n",
    "if args.warmup_epochs:\n",
    "    print(f\"Warmup begins\")\n",
    "    no_decay, decay = model.get_params()\n",
    "    optimizer = get_optimizer(decay_params=decay,\n",
    "                              no_decay_params=no_decay,\n",
    "                              lr=args.learning_rate / args.warmup_epochs,\n",
    "                              momentum=args.momentum,\n",
    "                              weight_decay=args.weight_decay\n",
    "                )\n",
    "    warm_scheduler = optim.lr_scheduler.LambdaLR(optimizer,\n",
    "                                                 lambda epoch_ix: (epoch_ix + 1)) # 0 indexed epochs\n",
    "    training_loop(\n",
    "        name=exp_name,\n",
    "        model=model,\n",
    "        opt=optimizer,\n",
    "        scheduler=warm_scheduler,\n",
    "        train_loader=train_data,\n",
    "        eval_loader=eval_data,\n",
    "        loss_fn=F.cross_entropy,\n",
    "        metric_fn=accuracy,\n",
    "        n_epochs=args.warmup_epochs,\n",
    "        device=device,\n",
    "        print_every=1000,\n",
    "        write_every=100,\n",
    "        check_every=0,\n",
    "    )\n",
    "no_decay, decay = model.get_params()\n",
    "optimizer = get_optimizer(decay_params=decay,\n",
    "                          no_decay_params=no_decay,\n",
    "                          lr=args.learning_rate,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "if not args.cosine_lr:\n",
    "    base_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.decay_interval, gamma=args.decay_gamma)\n",
    "else:\n",
    "    base_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.num_epochs, 0)\n",
    "print(f\"Post-warmup begins\")\n",
    "\n",
    "training_loop(\n",
    "    name=exp_name,\n",
    "    model=model,\n",
    "    opt=optimizer,\n",
    "    scheduler=base_scheduler,\n",
    "    train_loader=train_data,\n",
    "    eval_loader=eval_data,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    metric_fn=accuracy,\n",
    "    n_epochs=args.num_epochs,\n",
    "    device=device,\n",
    "    print_every=1000,\n",
    "    write_every=100,\n",
    "    check_every=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4df30-bc92-479d-9a11-ecea0a746c48",
   "metadata": {},
   "source": [
    "### Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6c0cc-e2fe-41dd-a70d-c3adc6ce4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.load(\n",
    "    os.path.join(os.path.join(\"data\", \"checkpoints\"), f\"{exp_name}-50000.pt\"),\n",
    "    map_location=device,\n",
    ")\n",
    "model.load_state_dict(loaded[\"model_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8ac43-84fe-4a80-952d-9faa3458a96e",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5372f-e76b-41d8-80dd-1856c2c074de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, should_be_none = get_image_data_loader(\n",
    "    args.dataset_name,\n",
    "    train=False,\n",
    "    val_share=0.1,\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size,\n",
    "    single_batch=False,\n",
    ")\n",
    "assert should_be_none is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa89803-602e-4d2c-8a16-269f95016eef",
   "metadata": {},
   "source": [
    "### Evaluated the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464b1cf-6dcd-4f74-bfbb-7f8e83be0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(\n",
    "    test_loader=test_loader,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    metric_fn=accuracy,\n",
    "    plot=True,\n",
    "    loss_fn=F.cross_entropy,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
